{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ライブラリをインポート\n",
    "import shutil\n",
    "\n",
    "from google.cloud import speech\n",
    "import io\n",
    "import os\n",
    "import glob\n",
    "import ffmpeg\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import int16\n",
    "import wave\n",
    "import struct\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import soundfile # audio file のbit数を変換するために利用するライブラリ\n",
    "\n",
    "# keyを指定\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '../Transcription/key/credentials.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# 文字起こし関数(モノラルチャンネルver)\n",
    "def transcription_wav(audio_file, box, string_data):\n",
    "    # 音声ファイルの読み込み\n",
    "    with io.open(audio_file, 'rb') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # APIパラメータの作成\n",
    "    audio = speech.RecognitionAudio(content = content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        # 都度エンコーディングする場合は、LINEAR16 しない場合は、ENCODING_UNSPECIFIED\n",
    "        # hertzはwavファイルによっては変更する必要があるかもしれないです。自分の場合は32000に指定しろと言われました\n",
    "        encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz = 8000,\n",
    "        language_code = \"ja-JP\",\n",
    "        #enable_word_time_offsets=True\n",
    "    )\n",
    "\n",
    "    # APIの呼び出し\n",
    "    client = speech.SpeechClient()\n",
    "    response = client.recognize(config = config, audio = audio)\n",
    "\n",
    "    # 結果の表示\n",
    "    # for result in response.results:\n",
    "    #     print(result.alternatives[0].transcript)\n",
    "    for i, result in enumerate(response.results):\n",
    "        # print(result)\n",
    "        # print(i)\n",
    "        alternative = result.alternatives[0]\n",
    "        print('-'*20)\n",
    "        print('現在文字起こし中です')\n",
    "        # print('first alternative of result {}'.format(i))\n",
    "        # print(u'Transcript:{}'.format(alternative.transcript))\n",
    "        # print(u'Channel Tag:{}'.format(result.channel_tag))\n",
    "        # print('second is ===', result.result_end_time)\n",
    "        item = [format(alternative.transcript), result.result_end_time, string_data]\n",
    "        box.append(item)\n",
    "    print('文字起こしを終了します')\n",
    "    return box"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# wavファイルを59秒間隔で分割する関数\n",
    "def cut_wav(audio_chang_wav, time, wav_cut_dir):\n",
    "    wr = wave.open(audio_chang_wav, \"r\")\n",
    "\n",
    "    # wav情報を取得\n",
    "    ch = wr.getnchannels()\n",
    "    width = wr.getsampwidth()\n",
    "    fr = wr.getframerate()\n",
    "    fn = wr.getnframes()\n",
    "    total_time = 1.0 * fn / fr\n",
    "    integer = math.floor(total_time)\n",
    "    t = int(time)\n",
    "    frames = int(ch * fr * t)\n",
    "    # 小数点切り上げ（1分に満たない最後のシーンを出力するため）\n",
    "    num_cut = int(math.ceil(integer / t))\n",
    "    data = wr.readframes(wr.getnframes())\n",
    "    wr.close()\n",
    "\n",
    "    X = np.frombuffer(data, dtype=int16)\n",
    "\n",
    "    for i in range(num_cut):\n",
    "        outf = wav_cut_dir + str(i) + \".wav\"\n",
    "        start_cut = int(i * frames)\n",
    "        end_cut = int(i * frames + frames)\n",
    "        print(start_cut)\n",
    "        print(end_cut)\n",
    "        Y = X[start_cut:end_cut]\n",
    "        outd = struct.pack(\"h\" * len(Y), *Y)\n",
    "\n",
    "        # 書き出し\n",
    "        ww = wave.open(outf, \"w\")\n",
    "        ww.setnchannels(ch)\n",
    "        ww.setsampwidth(width)\n",
    "        ww.setframerate(fr)\n",
    "        ww.writeframes(outd)\n",
    "        ww.close()\n",
    "    print('音声のカットを終了します')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "\n",
    "# いただいたファイルの音声ファイルのbit数が8bitだったので変換時に16bitに変換しろとエラーが出た\n",
    "# bit数を変換する関数\n",
    "def bit_change(audio_file_path, subtype):\n",
    "    data, fs = soundfile.read(audio_file_path)\n",
    "    soundfile.write('../Transcription/16bit_audio/bit_change_audio.wav', data, fs, subtype=subtype)\n",
    "    print('bit数の変換ファイルの出力が終了しました。')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# ステレオチャンネルの音声の文字起こしをする関数\n",
    "def transcription_wav_stereo(audio_file, box, string_data):\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(audio_file, 'rb') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding = speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz = 8000,\n",
    "        language_code = 'ja-JP',\n",
    "        audio_channel_count = 2,\n",
    "        enable_separate_recognition_per_channel = True,\n",
    "        # Trueにすると拡張モデルを利用する。何も指定しなかったら通常のモード（有料です）\n",
    "        use_enhanced=True,\n",
    "        # 機械学習モデルを選択できるので、それで電話通話を選択する。\n",
    "        model=\"phone_call\",\n",
    "    )\n",
    "\n",
    "    response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "    for i, result in enumerate(response.results):\n",
    "        alternative = result.alternatives[0]\n",
    "        print('-'*20)\n",
    "        #print('現在文字起こし中です')\n",
    "        # print('first alternative of result {}'.format(i))\n",
    "        # print(u'Transcript:{}'.format(alternative.transcript))\n",
    "        # print(u'Channel Tag:{}'.format(result.channel_tag))\n",
    "        # print('second is ===', result.result_end_time)\n",
    "        item = [alternative.transcript, result.channel_tag, result.result_end_time, string_data]\n",
    "        box.append(item)\n",
    "\n",
    "    print('文字起こしを終了します。')\n",
    "    return box\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Transcription/audio/ステレオaudio_change.wav'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/wx/51t4bgys7n5__g6ky336nqwm0000gn/T/ipykernel_1756/1026784308.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;31m# 試しに実行\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[0maudio_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'../Transcription/audio/ステレオaudio_change.wav'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m \u001B[0mstereo_channel_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maudio_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wx/51t4bgys7n5__g6ky336nqwm0000gn/T/ipykernel_1756/1026784308.py\u001B[0m in \u001B[0;36mstereo_channel_split\u001B[0;34m(stereo_audio)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# ステレオチャンネルの音声をleft, rightで分割して出力する関数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mstereo_channel_split\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstereo_audio\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0msound\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAudioSegment\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstereo_audio\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m     \u001B[0;31m# チャンネル数\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0mchannel_count\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msound\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mchannels\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/pydub/audio_segment.py\u001B[0m in \u001B[0;36mfrom_file\u001B[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001B[0m\n\u001B[1;32m    649\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    650\u001B[0m             \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 651\u001B[0;31m         \u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mclose_file\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_fd_or_path_or_tempfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtempfile\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    652\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    653\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mformat\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/pydub/utils.py\u001B[0m in \u001B[0;36m_fd_or_path_or_tempfile\u001B[0;34m(fd, mode, tempfile)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbasestring\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m         \u001B[0mfd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfd\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m         \u001B[0mclose_fd\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../Transcription/audio/ステレオaudio_change.wav'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ステレオチャンネルの音声をleft, rightで分割して出力する関数\n",
    "def stereo_channel_split(stereo_audio):\n",
    "    sound = AudioSegment.from_file(stereo_audio)\n",
    "    # チャンネル数\n",
    "    channel_count = sound.channels\n",
    "    # frame_rate = speech to text でいうところのhertz\n",
    "    frames_per_second = sound.frame_rate\n",
    "    # ファイルの音声の長さ（秒）\n",
    "    duration = sound.duration_seconds\n",
    "    # 音声ファイルをnumpyで変換\n",
    "    sound_array = np.array(sound.get_array_of_samples())\n",
    "    # 右左に分割\n",
    "    left_sound = sound_array[0:len(sound_array):2]\n",
    "    right_sound = sound_array[1:len(sound_array):2]\n",
    "    # 音声データの書き出し\n",
    "    write('left_audio.wav', frames_per_second, left_sound)\n",
    "    write('right_audio.wav', frames_per_second, right_sound)\n",
    "    print('音声の分割が終了しました')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "\n",
    "# 複数のオーディオがあるフォルダ内のwavファイルのpathを取得する\n",
    "def audio_file_path_getter(check_path):\n",
    "    path_name = glob.glob(check_path)\n",
    "    print('pathの数は===', len(path_name))\n",
    "    return path_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# audioのファイル名を取得する関数\n",
    "def audio_name_getter(audio_folder_path):\n",
    "    name_list = []\n",
    "    file_name = os.listdir(audio_folder_path)\n",
    "    for item in file_name:\n",
    "        # pathから名前のところだけを取得する\n",
    "        name_list.append(os.path.basename(item).split('.', 1)[0])\n",
    "    return name_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# timestampを本来の時間に戻す関数\n",
    "def calc_audio_time(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # audioを59秒ごとにカットしているので、audio_numの番号 * 59秒で本来の時間に戻してtimestampを更新\n",
    "        dataframe.at[index, 'new_time_stamp'] = row['new_time_stamp'] + (int(row['audio_num']) * 59)\n",
    "    return  dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# 音声取得〜整形〜文字起こしまでを一括できるように関数化してみた\n",
    "def main():\n",
    "    # 音声ファイルが全部でいくつあるのかを確認して、それぞれのpathを全て取得する\n",
    "    raw_audio_folder = '../Transcription/audio/*.wav'\n",
    "    audio_file = audio_file_path_getter(raw_audio_folder)\n",
    "    print(audio_file)\n",
    "\n",
    "    # 音声ファイルの名前だけを取得する（最後にテキストファイルの名前に利用する）\n",
    "    raw_audio_name = '../Transcription/audio/'\n",
    "    audio_name = audio_name_getter(raw_audio_name)\n",
    "    print(audio_name)\n",
    "    # # テスト用\n",
    "    # audio_file = ['../Transcription/audio/20220411322717_140250_59883_20220411322717.wav']\n",
    "    # audio_name = ['sample_create_1']\n",
    "    # pathの数だけ実行する\n",
    "    for audio, name in zip(audio_file, audio_name):\n",
    "        # 各音声ファイルの出力結果を格納するリスト 音声ファイルのpathが更新される度、空に戻すためにここに配置\n",
    "        text_save_list = []\n",
    "        print(audio)\n",
    "        # audioのbit数を16bitに変換する\n",
    "        bit_change(audio, 'PCM_16')\n",
    "        # 音声ファイルを59秒ごとに切り分けてfileに出力する\n",
    "        audio_file = '../Transcription/16bit_audio/bit_change_audio.wav'\n",
    "        save_cut_wav = '../Transcription/test_file/'\n",
    "        cut_wav(audio_file, 59, save_cut_wav)\n",
    "\n",
    "        # cutしたaudioファイルのpathを取得する\n",
    "        cut_audio = '../Transcription/test_file/*.wav'\n",
    "        cut_audio_file = audio_file_path_getter(cut_audio)\n",
    "\n",
    "        # 文字起こしを実行する\n",
    "        # 本来はlen(cut_audio_file)\n",
    "        for item in range(len(cut_audio_file)):\n",
    "\n",
    "            #これで指定しないと、wavファイルの順番がバラバラで読み込まれてしまう\n",
    "            now_wav_file ='../Transcription/test_file/'+str(item) +'.wav'\n",
    "            # ステレオチャンネルの文字起こしを実行\n",
    "            transcription_wav_stereo(now_wav_file, text_save_list, item)\n",
    "\n",
    "        # 文字起こしした結果をdataframeに変換する\n",
    "        result_df = pd.DataFrame(text_save_list, columns=['text', 'tag', 'timestamp', 'audio_num'])\n",
    "\n",
    "        # 出力されたタイムスタンプを整数値に変換する\n",
    "        result_df['new_time_stamp'] = result_df['timestamp'].dt.total_seconds()\n",
    "        # timestampの値を本来の時間に戻す\n",
    "        result_df = calc_audio_time(result_df)\n",
    "\n",
    "        result_df.to_csv('../Transcription/text_csv/transcription_'+str(name)+'.csv')\n",
    "\n",
    "        # カットしたaudioを削除する\n",
    "        for item in cut_audio_file:\n",
    "            os.remove(item)\n",
    "\n",
    "        print('音声ファイルの文字起こしを終了しました！')\n",
    "\n",
    "    print('実行を終了します')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathの数は=== 1\n",
      "['../Transcription/audio/20220411322717_140250_59883_20220411322717.wav']\n",
      "['20220411322717_140250_59883_20220411322717', '']\n",
      "../Transcription/audio/20220411322717_140250_59883_20220411322717.wav\n",
      "bit数の変換ファイルの出力が終了しました。\n",
      "0\n",
      "944000\n",
      "944000\n",
      "1888000\n",
      "1888000\n",
      "2832000\n",
      "2832000\n",
      "3776000\n",
      "3776000\n",
      "4720000\n",
      "4720000\n",
      "5664000\n",
      "5664000\n",
      "6608000\n",
      "6608000\n",
      "7552000\n",
      "7552000\n",
      "8496000\n",
      "8496000\n",
      "9440000\n",
      "音声のカットを終了します\n",
      "pathの数は=== 10\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "文字起こしを終了します。\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "文字起こしを終了します。\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/wx/51t4bgys7n5__g6ky336nqwm0000gn/T/ipykernel_1756/3773630099.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wx/51t4bgys7n5__g6ky336nqwm0000gn/T/ipykernel_1756/920613431.py\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m             \u001B[0mnow_wav_file\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;34m'../Transcription/test_file/'\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m\u001B[0;34m'.wav'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m             \u001B[0;31m# ステレオチャンネルの文字起こしを実行\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m             \u001B[0mtranscription_wav_stereo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnow_wav_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtext_save_list\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;31m# 文字起こしした結果をdataframeに変換する\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/wx/51t4bgys7n5__g6ky336nqwm0000gn/T/ipykernel_1756/2348915762.py\u001B[0m in \u001B[0;36mtranscription_wav_stereo\u001B[0;34m(audio_file, box, string_data)\u001B[0m\n\u001B[1;32m     20\u001B[0m     )\n\u001B[1;32m     21\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 22\u001B[0;31m     \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mclient\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecognize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maudio\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maudio\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     23\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/google/cloud/speech_v1/services/speech/client.py\u001B[0m in \u001B[0;36mrecognize\u001B[0;34m(self, request, config, audio, retry, timeout, metadata)\u001B[0m\n\u001B[1;32m    517\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    518\u001B[0m         \u001B[0;31m# Send the request.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 519\u001B[0;31m         \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mrpc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mretry\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mretry\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetadata\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmetadata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    520\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    521\u001B[0m         \u001B[0;31m# Done; return the response.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, timeout, retry, *args, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m             \u001B[0mkwargs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"metadata\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmetadata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    153\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 154\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapped_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    155\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/google/api_core/retry.py\u001B[0m in \u001B[0;36mretry_wrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    286\u001B[0m                 \u001B[0msleep_generator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    287\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_deadline\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 288\u001B[0;31m                 \u001B[0mon_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mon_error\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    289\u001B[0m             )\n\u001B[1;32m    290\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/google/api_core/retry.py\u001B[0m in \u001B[0;36mretry_target\u001B[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001B[0m\n\u001B[1;32m    188\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0msleep\u001B[0m \u001B[0;32min\u001B[0m \u001B[0msleep_generator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    189\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 190\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    191\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m         \u001B[0;31m# pylint: disable=broad-except\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001B[0m in \u001B[0;36merror_remapped_callable\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0merror_remapped_callable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mcallable_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mgrpc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRpcError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mexceptions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_grpc_error\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mexc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/grpc/_channel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001B[0m\n\u001B[1;32m    943\u001B[0m                  compression=None):\n\u001B[1;32m    944\u001B[0m         state, call, = self._blocking(request, timeout, metadata, credentials,\n\u001B[0;32m--> 945\u001B[0;31m                                       wait_for_ready, compression)\n\u001B[0m\u001B[1;32m    946\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_end_unary_response_blocking\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcall\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    947\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/training_python/venv/lib/python3.7/site-packages/grpc/_channel.py\u001B[0m in \u001B[0;36m_blocking\u001B[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001B[0m\n\u001B[1;32m    931\u001B[0m                     \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m                 ),), self._context)\n\u001B[0;32m--> 933\u001B[0;31m             \u001B[0mevent\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnext_event\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    934\u001B[0m             \u001B[0m_handle_event\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevent\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_response_deserializer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcall\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001B[0m in \u001B[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001B[0m in \u001B[0;36mgrpc._cython.cygrpc._next_call_event\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\u001B[0m in \u001B[0;36mgrpc._cython.cygrpc._next_call_event\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001B[0m in \u001B[0;36mgrpc._cython.cygrpc._latent_event\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi\u001B[0m in \u001B[0;36mgrpc._cython.cygrpc._next\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# audio_path = '../Transcription/audio/ステレオaudio.wav'\n",
    "# change_subtype = 'PCM_16'\n",
    "# # bit数を変換するための関数実行\n",
    "# bit_change(audio_path,change_subtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #いきなり長いファイルは処理が長くなってしまうので、適当に30秒ほどのデータを作成するときに利用\n",
    "# sound = AudioSegment.from_file('../Transcription/audio/ステレオaudio.wav', format='wav')\n",
    "# print(len(sound))\n",
    "# # msで記述されている（5~1000秒の切り出し）\n",
    "# sound1 = sound[5000:59000]\n",
    "# sound1.export('output.wav', format='wav')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# APIに直接遅れるのが60秒未満なので、59秒で設定している\n",
    "# 1分以上の場合は、uriでの扱いになる？\n",
    "# time = 59\n",
    "# audio_change_wav = '../Transcription/16bit_audio/bit_change_audio.wav'\n",
    "# wav_cut_dir = '../Transcription/test_file/'\n",
    "# # 音声ファイルをカットする関数\n",
    "# cut_wav(audio_change_wav,time,  wav_cut_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}