{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import MeCab\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import urllib.request ,urllib.error #urlを読み込むためのライブラリ\n",
    "from wordcloud import WordCloud # ワードクラウドのライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# 文字起こしされたcsvファイルを保存しているフォルダからcsvファイルのpathを取得\n",
    "def csv_file_path_getter(csv_folder):\n",
    "    path_name = glob.glob(csv_folder)\n",
    "    print('pathの数は===', len(path_name))\n",
    "    return path_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# csv fileの名前を取得する関数\n",
    "def csv_name_getter(csv_folder):\n",
    "    name_list = []\n",
    "    file_name = os.listdir(csv_folder)\n",
    "    for item in file_name:\n",
    "        # pathのところからcsvファイルの名前だけを取得\n",
    "        name_list.append(os.path.basename(item).split('.',1)[0])\n",
    "    return name_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# データフレームを作成して、空白行を削除したものを返す関数\n",
    "def create_data_frame(csv_path):\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    print('-'*20)\n",
    "    print(dataframe.isnull().sum())\n",
    "    print('-'*20)\n",
    "    # 必要な行だけを抽出\n",
    "    dataframe = dataframe[['text', 'tag', 'timestamp']]\n",
    "    # text列にNanで格納されている行は削除する\n",
    "    dataframe = dataframe.dropna(subset=['text'])\n",
    "    # インデックス番号を振り直し\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "    # 念の為確認する\n",
    "    print('-'*20)\n",
    "    print(dataframe.isnull().sum())\n",
    "    print('-'*20)\n",
    "    print('dataframe length is ===', len(dataframe))\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# 形態素解析を実施して、動詞、名詞、形容詞を取得する関数\n",
    "def word_separation_sentence_getter(dataframe):\n",
    "    # mecabを準備\n",
    "    # 固有名詞や新規単語に強いneologdを利用しています\n",
    "    mecab = MeCab.Tagger('-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "\n",
    "    sentence_list = []\n",
    "    for text in dataframe['text']:\n",
    "        noun_list = [] # 名詞を格納するリスト\n",
    "        verb_list = [] # 動詞を格納するリスト\n",
    "        adjective_list = []  # 形容詞を格納するリスト\n",
    "        mecab.parse('')\n",
    "        node = mecab.parseToNode(text)\n",
    "        #print('now text is ===',text)\n",
    "        while node:\n",
    "            # 品詞が名詞なら\n",
    "            if node.feature.split(',')[0] == '名詞':\n",
    "                # print('-'*20)\n",
    "                # print(node.surface, '++++++',node.feature)\n",
    "                noun_list.append(node.surface)\n",
    "            # 品詞が動詞なら\n",
    "            elif node.feature.split(',')[0] == '動詞':\n",
    "                # print('#'*20)\n",
    "                # print(node.surface, '++++++',node.feature)\n",
    "                verb_list.append(node.surface)\n",
    "            # 品詞が形容詞なら\n",
    "            elif node.feature.split(',')[0] == '形容詞':\n",
    "                # print('#'*20)\n",
    "                # print(node.surface, '++++++',node.feature)\n",
    "                adjective_list.append(node.surface)\n",
    "            else:pass\n",
    "            # 書き忘れると無限ループになるので注意！\n",
    "            node = node.next\n",
    "\n",
    "        item_list = [noun_list, verb_list, adjective_list]\n",
    "        sentence_list.append(item_list)\n",
    "    print('分かち書きと単語の格納が終了しました')\n",
    "    return sentence_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "# 分かち書きして取得した品詞たちを','→' '空白で区切って格納する\n",
    "def append_dataframe(dataframe, sentence_list):\n",
    "    dataframe[['名詞', '動詞', '形容詞']] =sentence_list\n",
    "    for column in dataframe.columns.values:\n",
    "        # デフォルトであった列は空白で区切る必要がないので、それ以外のカラム名を特定するためのif文\n",
    "        if column != 'text' and column != 'tag' and column != 'timestamp':\n",
    "            dataframe[column] = dataframe[column].apply(' '.join)\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# ワードクラウドで表現したい品詞をデータフレームから抽出する関数\n",
    "def choose_part_of_speech(dataframe, part):\n",
    "    part_of_speech_list = []\n",
    "    for word in dataframe[part]:\n",
    "        part_of_speech_list.append(word)\n",
    "\n",
    "    return part_of_speech_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# リストを文字列に変換する関数\n",
    "def join_list_str(list):\n",
    "    return ' '.join(list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# ストップワードを準備する関数\n",
    "def create_stop_words():\n",
    "\n",
    "    sloth_lib_path = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    sloth_lib_file = urllib.request.urlopen(sloth_lib_path)\n",
    "    # 読み込んだサイトからストップワードを読み込んで、utf-8でデコードしてから1単語ずつに分けて格納する\n",
    "    sloth_lib_stop_words = [line.decode('utf-8').strip() for line in sloth_lib_file]\n",
    "    # 格納した単語のうちu''(空白の文字列を除外する)\n",
    "    sloth_lib_stop_words = [ss for ss in sloth_lib_stop_words if not ss==u'']\n",
    "\n",
    "    stop_words_list = []\n",
    "    f = open('more_stop_word.txt')\n",
    "    txt_file = f.readlines()\n",
    "    f.close()\n",
    "    # 自分用意した追加のストップワードをmore_stop_wordに格納する\n",
    "    more_stop_word = [line.strip() for line in txt_file]\n",
    "    # 自分で用意したストップワードの中に空白文字列を除外して格納\n",
    "    more_stop_word = [ss for ss in more_stop_word if not ss==u'']\n",
    "\n",
    "    stop_words_list += more_stop_word\n",
    "    stop_words_list += sloth_lib_stop_words\n",
    "    # 重複があった場合削除するため\n",
    "    stop_words_list = set(stop_words_list)\n",
    "\n",
    "    return stop_words_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# ストップワードを除外する関数\n",
    "def drop_stop_words(text, stopwords):\n",
    "    change_text = []\n",
    "    for token in text.lower().split(\" \"):\n",
    "        if token != \"\":\n",
    "            if token not in stopwords:\n",
    "                change_text.append(token)\n",
    "            # else:\n",
    "            #     print('この単語は除外します=====',token) # 除外したい単語が見たい時はonにしてください\n",
    "    return change_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# ワードクラウドを書き出す関数\n",
    "def create_word_cloud(word_list, title):\n",
    "    font_path = '/Library/Fonts/Arial Unicode.ttf'\n",
    "    word_cloud = WordCloud(\n",
    "                        width=480,\n",
    "                        height=320,\n",
    "                        background_color='white',\n",
    "                        font_path=font_path,\n",
    "                        max_words = 200,\n",
    "                        max_font_size=100,\n",
    "                        random_state=42,\n",
    "    )\n",
    "    word_cloud.generate(word_list)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.title(title)\n",
    "    plt.imshow(word_cloud)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# 単語をカウントしてデータフレームで返す関数\n",
    "def count_word(text_list):\n",
    "    # 空の辞書を準備\n",
    "    word_freq_dic = {}\n",
    "    for word in text_list:\n",
    "        #　もし、辞書に単語が存在していたら\n",
    "        if word in word_freq_dic:\n",
    "            # countを+1\n",
    "            word_freq_dic[word] += 1\n",
    "        else:\n",
    "            # ない場合は、新しい単語として登録 +1カウント\n",
    "            word_freq_dic.setdefault(word, 1)\n",
    "\n",
    "    # valueで並び替える[0]にするとkeyで並び替える(降順)\n",
    "    word_freq_dic = sorted(word_freq_dic.items(), key=lambda x:x[1], reverse=True)\n",
    "    # データフレームを作成する\n",
    "    dataframe = pd.DataFrame(word_freq_dic, columns=['word', 'count'])\n",
    "\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "#カウントされたデータフレームがの中身を確認するときに関数\n",
    "def check_dataframe_element(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        print(dataframe.at[index, 'word'],'count num ====', dataframe.at[index, 'count'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "\n",
    "# １人の単語を可視化するために利用する関数(ぐりぐり動かすことができるグラフ）\n",
    "def create_plotly_bar_plot(dataframe):\n",
    "    trace = px.bar(\n",
    "        dataframe,\n",
    "        x = 'count',\n",
    "        y = 'word',\n",
    "        width=600,\n",
    "        height=800,\n",
    "        title = 'word cloud use text item'\n",
    "\n",
    "    )\n",
    "    fig = trace\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "\n",
    "#　seabornでグラフを可視化する時に利用\n",
    "def create_seaborn_bar_chart(dataframe, color):\n",
    "    fig = plt.subplots(figsize=(12,12))\n",
    "\n",
    "    sns.barplot(data = dataframe,\n",
    "                x = 'count',\n",
    "                y = 'word',\n",
    "                color = color\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "\n",
    "# 全員まとめて実行するのかそれぞれの話者ごとで実行するのかを選択する関数\n",
    "def total_or_separate(dataframe, which_play):\n",
    "    dataframe_list = []\n",
    "    #Tureの場合は分割して、複数人分のデータフレームを格納したリストを返す\n",
    "    if which_play:\n",
    "        for tag_num in dataframe['tag'].unique():\n",
    "            mem_dataframe = dataframe[dataframe['tag'] == tag_num]\n",
    "            dataframe_list.append(mem_dataframe)\n",
    "        return dataframe_list\n",
    "    # Falseの場合はそのままデータフレームを返す\n",
    "    else:\n",
    "        return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# 品詞分類〜ワードクラウドの可視化をまとめて関数化（全体用と個人用で少し動作を変更するため）\n",
    "def separation_to_create_cloud(dataframe, name):\n",
    "\n",
    "    part_word = choose_part_of_speech(dataframe, '名詞') # ワードクラウドで書き起こしたい品詞の列をリストとして取得してくる\n",
    "    # 現状はここで品詞を指定\n",
    "    part_word = join_list_str(part_word)\n",
    "\n",
    "    part_word = drop_stop_words(part_word, create_stop_words()) # ストップワードを除外する\n",
    "\n",
    "    count_df = count_word(part_word) #ここで単語のカウントを実施する(word : countの状態で記録している)\n",
    "    # check_dataframe_element(count_df) # count_dfが確認したい時に実行してください\n",
    "\n",
    "    part_word = join_list_str(part_word) # word_cloudに食べさせても問題のない形に整形する\n",
    "    create_word_cloud(part_word, name)\n",
    "\n",
    "    # create_plotly_bar_plot(count_df) # plotlyによる可視化\n",
    "\n",
    "    count_df = count_df[count_df['count'] >= 3] # 全て可視化すると単語が潰れてしまうため出現数が3回以上の単語に限定\n",
    "    create_seaborn_bar_chart(count_df, 'green') # seabornによる可視化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# 文字起こししたcsvファイルをもとにワードクラウドを作成して、ローカルに保存するところまでを関数化\n",
    "def main():\n",
    "\n",
    "    # 文字起こしされたcsvファイルのpath\n",
    "    folder_path = '../Transcription/text_csv/*.csv'\n",
    "    # ワードクラウドにつける名前を取得するためのpath\n",
    "    name_path = '../Transcription/text_csv/'\n",
    "    csv_path = csv_file_path_getter(folder_path)\n",
    "    csv_name = csv_name_getter(name_path)\n",
    "    csv_name = list(filter(None, csv_name))\n",
    "    print(csv_path)\n",
    "    print(csv_name)\n",
    "    # 練習用\n",
    "    # test_folder_path  = ['../Transcription/text_csv/transcription_ステレオaudio.csv']\n",
    "    # test_csv_path = ['練習']\n",
    "\n",
    "    for path, save_name in zip(csv_path, csv_name):\n",
    "\n",
    "        separate = False # Trueなら別々で実行　Falseならまとめて実行\n",
    "\n",
    "\n",
    "        df = create_data_frame(path) # データフレームをある程度整形した状態で作成\n",
    "        word_list = word_separation_sentence_getter(df) # テキストを品詞分類して、返す（名詞、動詞、形容詞）\n",
    "        print(len(word_list))\n",
    "        df = append_dataframe(df, word_list) # データフレームに品詞列を結合させる\n",
    "        print('dataframe length is ===', len(df))\n",
    "\n",
    "        df = total_or_separate(df, separate) # 複数人に分割 or 全員まとめて\n",
    "        if separate:\n",
    "            for mem_df in df:\n",
    "                separation_to_create_cloud(mem_df, save_name)\n",
    "        else:\n",
    "            separation_to_create_cloud(df, save_name)\n",
    "\n",
    "        return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = main()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# ngramのための試行錯誤コード\n",
    "def test_fig(dff):\n",
    "    # 積み上げグラフでみると特徴があるかも？\n",
    "    test_data = []\n",
    "    for mem in dff['tag'].unique():\n",
    "        df_mem = dff[dff['tag'] == mem]\n",
    "        part_word = choose_part_of_speech(df_mem, '名詞')\n",
    "        part_word = join_list_str(part_word)\n",
    "        part_word = drop_stop_words(part_word, create_stop_words())\n",
    "        count_df = count_word(part_word)\n",
    "        count_df['tag'] = mem\n",
    "        display(count_df.head())\n",
    "        test_data.append(count_df)\n",
    "\n",
    "    df1 = test_data[0]\n",
    "    df2 = test_data[1]\n",
    "    df_concat = pd.concat([df1, df2])\n",
    "\n",
    "    df1 = df1.sort_values('count')\n",
    "    df2 = df1.sort_values('count')\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(10,30))\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "    ax1 = fig.add_subplot(1,2,1)\n",
    "    ax1.barh(df1['word'], df1['count'],color='red')\n",
    "    ax1.set_xlabel('出現回数')\n",
    "    ax1.set_ylabel('名詞リスト')\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.barh(df2['word'], df2['count'],color='blue')\n",
    "    ax2.set_xlabel('出現回数')\n",
    "    ax2.set_ylabel('名詞リスト')\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test_fig(df_test)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}