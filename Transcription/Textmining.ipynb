{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はい\t感動詞,*,*,*,*,*,はい,ハイ,ハイ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "本日\t名詞,副詞可能,*,*,*,*,本日,ホンジツ,ホンジツ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "鬼滅の刃\t名詞,固有名詞,一般,*,*,*,鬼滅の刃,キメツノヤイバ,キメツノヤイバ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "公開日\t名詞,固有名詞,一般,*,*,*,公開日,コウカイビ,コーカイビ\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "あり\t動詞,自立,*,*,五段・ラ行,連用形,ある,アリ,アリ\n",
      "ます\t助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "しかし\t接続詞,*,*,*,*,*,しかし,シカシ,シカシ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "もう\t副詞,一般,*,*,*,*,もう,モウ,モー\n",
      "一つ\t名詞,一般,*,*,*,*,一つ,ヒトツ,ヒトツ\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "映画館\t名詞,一般,*,*,*,*,映画館,エイガカン,エイガカン\n",
      "で\t助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "呪術廻戦\t名詞,固有名詞,一般,*,*,*,呪術廻戦,ジュジュツカイセン,ジュジュツカイセン\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "やっ\t動詞,自立,*,*,五段・ラ行,連用タ接続,やる,ヤッ,ヤッ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "いる\t動詞,非自立,*,*,一段,基本形,いる,イル,イル\n",
      "よ\t助詞,終助詞,*,*,*,*,よ,ヨ,ヨ\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n",
      "！\t記号,一般,*,*,*,*,！,！,！\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mecabを準備\n",
    "# 固有名詞や新規単語に強いneologdを利用しています\n",
    "mecab = MeCab.Tagger('-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "sent = 'はい、本日は、鬼滅の刃の公開日でもあります。しかし、もう一つの映画館では呪術廻戦がやっているよ！！'\n",
    "print(mecab.parse(sent))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " #### BOS/EOS,*,*,*,*,*,*,*,*\n",
      "はい #### 感動詞,*,*,*,*,*,はい,ハイ,ハイ\n",
      "、 #### 記号,読点,*,*,*,*,、,、,、\n",
      "本日 #### 名詞,副詞可能,*,*,*,*,本日,ホンジツ,ホンジツ\n",
      "は #### 助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "、 #### 記号,読点,*,*,*,*,、,、,、\n",
      "鬼滅の刃 #### 名詞,固有名詞,一般,*,*,*,鬼滅の刃,キメツノヤイバ,キメツノヤイバ\n",
      "の #### 助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "公開日 #### 名詞,固有名詞,一般,*,*,*,公開日,コウカイビ,コーカイビ\n",
      "で #### 助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "も #### 助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "あり #### 動詞,自立,*,*,五段・ラ行,連用形,ある,アリ,アリ\n",
      "ます #### 助動詞,*,*,*,特殊・マス,基本形,ます,マス,マス\n",
      "。 #### 記号,句点,*,*,*,*,。,。,。\n",
      "しかし #### 接続詞,*,*,*,*,*,しかし,シカシ,シカシ\n",
      "、 #### 記号,読点,*,*,*,*,、,、,、\n",
      "もう #### 副詞,一般,*,*,*,*,もう,モウ,モー\n",
      "一つ #### 名詞,一般,*,*,*,*,一つ,ヒトツ,ヒトツ\n",
      "の #### 助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "映画館 #### 名詞,一般,*,*,*,*,映画館,エイガカン,エイガカン\n",
      "で #### 助詞,格助詞,一般,*,*,*,で,デ,デ\n",
      "は #### 助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "呪術廻戦 #### 名詞,固有名詞,一般,*,*,*,呪術廻戦,ジュジュツカイセン,ジュジュツカイセン\n",
      "が #### 助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "やっ #### 動詞,自立,*,*,五段・ラ行,連用タ接続,やる,ヤッ,ヤッ\n",
      "て #### 助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "いる #### 動詞,非自立,*,*,一段,基本形,いる,イル,イル\n",
      "よ #### 助詞,終助詞,*,*,*,*,よ,ヨ,ヨ\n",
      "！ #### 記号,一般,*,*,*,*,！,！,！\n",
      "！ #### 記号,一般,*,*,*,*,！,！,！\n",
      " #### BOS/EOS,*,*,*,*,*,*,*,*\n"
     ]
    }
   ],
   "source": [
    "nodes = mecab.parseToNode(sent)\n",
    "while nodes:\n",
    "    print(nodes.surface,'####', nodes.feature)\n",
    "    # nextを書き忘れると無限ループになる\n",
    "    nodes = nodes.next"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import urllib.request ,urllib.error #urlを読み込むためのライブラリ\n",
    "from wordcloud import WordCloud # ワードクラウドのライブラリ\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 文字起こしされたcsvファイルを保存しているフォルダからcsvファイルのpathを取得\n",
    "def csv_file_path_getter(csv_folder):\n",
    "    path_name = glob.glob(csv_folder)\n",
    "    print('pathの数は===', len(path_name))\n",
    "    return path_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# csv fileの名前を取得する関数\n",
    "def csv_name_getter(csv_folder):\n",
    "    name_list = []\n",
    "    file_name = os.listdir(csv_folder)\n",
    "    for item in file_name:\n",
    "        # pathのところからcsvファイルの名前だけを取得\n",
    "        name_list.append(os.path.basename(item).split('.',1)[0])\n",
    "    return name_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# データフレームを作成して、空白行を削除したものを返す関数\n",
    "def create_data_frame(csv_path):\n",
    "    dataframe = pd.read_csv(csv_path)\n",
    "    print('-'*20)\n",
    "    print(dataframe.isnull().sum())\n",
    "    print('-'*20)\n",
    "    # 必要な行だけを抽出\n",
    "    dataframe = dataframe[['text', 'tag', 'timestamp']]\n",
    "    # text列にNanで格納されている行は削除する\n",
    "    dataframe = dataframe.dropna(subset=['text'])\n",
    "    # インデックス番号を振り直し\n",
    "    dataframe = dataframe.reset_index(drop=True)\n",
    "    # 念の為確認する\n",
    "    print('-'*20)\n",
    "    print(dataframe.isnull().sum())\n",
    "    print('-'*20)\n",
    "    print('dataframe length is ===', len(dataframe))\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# 形態素解析を実施して、動詞、名詞、形容詞を取得する関数\n",
    "def word_separation_sentence_getter(dataframe):\n",
    "    # mecabを準備\n",
    "    # 固有名詞や新規単語に強いneologdを利用しています\n",
    "    mecab = MeCab.Tagger('-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd')\n",
    "\n",
    "    sentence_list = []\n",
    "    for text in dataframe['text']:\n",
    "        noun_list = [] # 名詞を格納するリスト\n",
    "        verb_list = [] # 動詞を格納するリスト\n",
    "        adjective_list = []  # 形容詞を格納するリスト\n",
    "        mecab.parse('')\n",
    "        node = mecab.parseToNode(text)\n",
    "        #print('now text is ===',text)\n",
    "        while node:\n",
    "            # 品詞が名詞なら\n",
    "            if node.feature.split(',')[0] == '名詞':\n",
    "                # print('-'*20)\n",
    "                # print(node.surface, '++++++',node.feature)\n",
    "                noun_list.append(node.surface)\n",
    "            # 品詞が動詞なら\n",
    "            elif node.feature.split(',')[0] == '動詞':\n",
    "                # print('#'*20)\n",
    "                # print(node.surface, '++++++',node.feature)\n",
    "                verb_list.append(node.surface)\n",
    "            # 品詞が形容詞なら\n",
    "            elif node.feature.split(',')[0] == '形容詞':\n",
    "                # print('#'*20)\n",
    "                # print(node.surface, '++++++',node.feature)\n",
    "                adjective_list.append(node.surface)\n",
    "            else:pass\n",
    "            # 書き忘れると無限ループになるので注意！\n",
    "            node = node.next\n",
    "\n",
    "        item_list = [noun_list, verb_list, adjective_list]\n",
    "        sentence_list.append(item_list)\n",
    "    print('分かち書きと単語の格納が終了しました')\n",
    "    return sentence_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# 分かち書きして取得した品詞たちを','→' '空白で区切って格納する\n",
    "def append_dataframe(dataframe, sentence_list):\n",
    "    dataframe[['名詞', '動詞', '形容詞']] =sentence_list\n",
    "    for column in dataframe.columns.values:\n",
    "        # デフォルトであった列は空白で区切る必要がないので、それ以外のカラム名を特定するためのif文\n",
    "        if column != 'text' and column != 'tag' and column != 'timestamp':\n",
    "            dataframe[column] = dataframe[column].apply(' '.join)\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# ワードクラウドで表現したい品詞をデータフレームから抽出する関数\n",
    "def choose_part_of_speech(dataframe, part):\n",
    "    part_of_speech_list = []\n",
    "    for word in dataframe[part]:\n",
    "        part_of_speech_list.append(word)\n",
    "\n",
    "    return part_of_speech_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# リストを文字列に変換する関数\n",
    "def join_list_str(list):\n",
    "    return ' '.join(list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# ストップワードを準備する関数\n",
    "def create_stop_words():\n",
    "\n",
    "    sloth_lib_path = 'http://svn.sourceforge.jp/svnroot/slothlib/CSharp/Version1/SlothLib/NLP/Filter/StopWord/word/Japanese.txt'\n",
    "    sloth_lib_file = urllib.request.urlopen(sloth_lib_path)\n",
    "    # 読み込んだサイトからストップワードを読み込んで、utf-8でデコードしてから1単語ずつに分けて格納する\n",
    "    sloth_lib_stop_words = [line.decode('utf-8').strip() for line in sloth_lib_file]\n",
    "    # 格納した単語のうちu''(空白の文字列を除外する)\n",
    "    sloth_lib_stop_words = [ss for ss in sloth_lib_stop_words if not ss==u'']\n",
    "\n",
    "    stop_words_list = []\n",
    "    f = open('more_stop_word.txt')\n",
    "    txt_file = f.readlines()\n",
    "    f.close()\n",
    "    # 自分用意した追加のストップワードをmore_stop_wordに格納する\n",
    "    more_stop_word = [line.strip() for line in txt_file]\n",
    "    # 自分で用意したストップワードの中に空白文字列を除外して格納\n",
    "    more_stop_word = [ss for ss in more_stop_word if not ss==u'']\n",
    "\n",
    "    stop_words_list += more_stop_word\n",
    "    stop_words_list += sloth_lib_stop_words\n",
    "    # 重複があった場合削除するため\n",
    "    stop_words_list = set(stop_words_list)\n",
    "\n",
    "    return stop_words_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "# ストップワードを除外する関数\n",
    "def drop_stop_words(text, stopwords):\n",
    "    change_text = []\n",
    "    for token in text.lower().split(\" \"):\n",
    "        if token != \"\":\n",
    "            if token not in stopwords:\n",
    "                change_text.append(token)\n",
    "            else:\n",
    "                print('この単語は除外します=====',token)\n",
    "    return change_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "# ワードクラウドを書き出す関数\n",
    "def create_word_cloud(word_list, title):\n",
    "    font_path = '/Library/Fonts/Arial Unicode.ttf'\n",
    "    word_cloud = WordCloud(\n",
    "                        width=480,\n",
    "                        height=320,\n",
    "                        background_color='white',\n",
    "                        font_path=font_path,\n",
    "                        max_words = 200,\n",
    "                        max_font_size=100,\n",
    "                        random_state=42,\n",
    "    )\n",
    "    word_cloud.generate(word_list)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plt.title(title)\n",
    "    plt.imshow(word_cloud)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "# 文字起こししたcsvファイルをもとにワードクラウドを作成して、ローカルに保存するところまでを関数化\n",
    "def main():\n",
    "\n",
    "    # 文字起こしされたcsvファイルのpath\n",
    "    folder_path = '../Transcription/text_csv/*.csv'\n",
    "    # ワードクラウドにつける名前を取得するためのpath\n",
    "    name_path = '../Transcription/text_csv/'\n",
    "    csv_path = csv_file_path_getter(folder_path)\n",
    "    csv_name = csv_name_getter(name_path)\n",
    "    print(csv_name)\n",
    "    # 練習用\n",
    "    test_folder_path  = ['../Transcription/text_csv/transcription_ステレオaudio.csv']\n",
    "    test_csv_path = ['練習']\n",
    "\n",
    "    for path, name in zip(test_folder_path, test_csv_path):\n",
    "        # データフレームをある程度整形した状態で作成\n",
    "        df = create_data_frame(path)\n",
    "        print('dataframe length is ===', len(df))\n",
    "        # テキストを品詞分類して、返す（名詞、動詞、形容詞）\n",
    "        word_list = word_separation_sentence_getter(df)\n",
    "        print(len(word_list))\n",
    "        # データフレームに品詞列を結合させる\n",
    "        df = append_dataframe(df, word_list)\n",
    "        # ワードクラウドで書き起こしたい品詞の列をリストとして取得してくる\n",
    "        part_word = choose_part_of_speech(df, '名詞') # 現状はここで品詞を指定\n",
    "        part_word = join_list_str(part_word)\n",
    "\n",
    "        # ストップワードを除外する\n",
    "        part_word = drop_stop_words(part_word, create_stop_words())\n",
    "        # word_cloudに食べさせても問題のない形に整形する\n",
    "        part_word = join_list_str(part_word)\n",
    "        #create_word_cloud(part_word, name)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathの数は=== 6\n",
      "['test_stereo_use_model', '', 'test_stereo', 'test_stereo_use_enhance_model', 'transcription_ステレオaudio', 'test_right', 'test_left']\n",
      "--------------------\n",
      "Unnamed: 0         0\n",
      "text              21\n",
      "tag                0\n",
      "timestamp          0\n",
      "audio_num          0\n",
      "new_time_stamp     0\n",
      "dtype: int64\n",
      "--------------------\n",
      "--------------------\n",
      "text         0\n",
      "tag          0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "--------------------\n",
      "dataframe length is === 150\n",
      "dataframe length is === 150\n",
      "分かち書きと単語の格納が終了しました\n",
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kawakamitatsuya/PycharmProjects/training_python/venv/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<http.client.HTTPResponse object at 0x7ff139ef7cf8>\n",
      "['の\\n', 'ん\\n', '\\n']\n",
      "この単語は除外します===== 様\n",
      "この単語は除外します===== 私\n",
      "この単語は除外します===== こと\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== これ\n",
      "この単語は除外します===== そちら\n",
      "この単語は除外します===== こちら\n",
      "この単語は除外します===== こちら\n",
      "この単語は除外します===== ため\n",
      "この単語は除外します===== とき\n",
      "この単語は除外します===== やつ\n",
      "この単語は除外します===== 上\n",
      "この単語は除外します===== もの\n",
      "この単語は除外します===== なん\n",
      "この単語は除外します===== もの\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== 一つ\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== 前\n",
      "この単語は除外します===== 一つ\n",
      "この単語は除外します===== 後\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== それぞれ\n",
      "この単語は除外します===== ごと\n",
      "この単語は除外します===== 方\n",
      "この単語は除外します===== こと\n",
      "この単語は除外します===== 場合\n",
      "この単語は除外します===== こと\n",
      "この単語は除外します===== 一つ\n",
      "この単語は除外します===== それぞれ\n",
      "この単語は除外します===== 一つ\n",
      "この単語は除外します===== それ\n",
      "この単語は除外します===== 場合\n",
      "この単語は除外します===== 形\n",
      "この単語は除外します===== 場合\n",
      "この単語は除外します===== これ\n",
      "この単語は除外します===== それ\n",
      "この単語は除外します===== こちら\n",
      "この単語は除外します===== こちら\n",
      "この単語は除外します===== 口\n",
      "この単語は除外します===== 方\n",
      "この単語は除外します===== 今\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== 的\n",
      "この単語は除外します===== ところ\n",
      "この単語は除外します===== そっち\n",
      "この単語は除外します===== 方\n",
      "この単語は除外します===== 方法\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== もの\n",
      "この単語は除外します===== あと\n",
      "この単語は除外します===== 中\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== 中\n",
      "この単語は除外します===== 方\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== これ\n",
      "この単語は除外します===== 前\n",
      "この単語は除外します===== 際\n",
      "この単語は除外します===== 時\n",
      "この単語は除外します===== それ\n",
      "この単語は除外します===== 話\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== 何\n",
      "この単語は除外します===== 結局\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== 何\n",
      "この単語は除外します===== 確か\n",
      "この単語は除外します===== そこ\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== こと\n",
      "この単語は除外します===== 以前\n",
      "この単語は除外します===== そこ\n",
      "この単語は除外します===== 数\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== 先\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== 何\n",
      "この単語は除外します===== みたい\n",
      "この単語は除外します===== こと\n",
      "この単語は除外します===== 先\n",
      "この単語は除外します===== 元\n",
      "この単語は除外します===== 先\n",
      "この単語は除外します===== 前\n",
      "この単語は除外します===== やつ\n",
      "この単語は除外します===== 何\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== あたり\n",
      "この単語は除外します===== もの\n",
      "この単語は除外します===== 点\n",
      "この単語は除外します===== 時\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== 先\n",
      "この単語は除外します===== 千\n",
      "この単語は除外します===== なん\n",
      "この単語は除外します===== 感じ\n",
      "この単語は除外します===== こちら\n",
      "この単語は除外します===== みたい\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== そこ\n",
      "この単語は除外します===== 何\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== の\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== 先\n",
      "この単語は除外します===== 先\n",
      "この単語は除外します===== もの\n",
      "この単語は除外します===== 元\n",
      "この単語は除外します===== やつ\n",
      "この単語は除外します===== これ\n",
      "この単語は除外します===== しよう\n",
      "この単語は除外します===== ため\n",
      "この単語は除外します===== ん\n",
      "この単語は除外します===== それ\n",
      "この単語は除外します===== あと\n",
      "この単語は除外します===== 感じ\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}